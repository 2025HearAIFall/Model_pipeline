# ======================================================
# Hand Bridge Socket.IO Server (Full Code)
# ======================================================

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from flask_socketio import SocketIO, emit, join_room, leave_room
import base64, io, os, torch, traceback, cv2, re
from PIL import Image
import numpy as np
import builtins
import mediapipe as mp

# ------------------------------------------------------
# 1. Path & Vocab Setup
# ------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FRONTEND_DIR = os.path.abspath(os.path.join(BASE_DIR, '..', 'frontend'))

class Vocabulary:
    def __init__(self, tokenizer=None, min_freq=2):
        self.tokenizer = tokenizer; self.itos = {}; self.stoi = {}
        self.min_freq = min_freq; self.pad_idx = 0; self.sos_idx = 1; self.eos_idx = 2
    def __len__(self): return len(self.itos)

def simple_tokenizer(text): return text.split(' ')

builtins.Vocabulary = Vocabulary
builtins.simple_tokenizer = simple_tokenizer

# ------------------------------------------------------
# 2. Load Models
# ------------------------------------------------------
# inference.pyê°€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
from inference import (
    vocab, encoder_session, decoder_session,          
    gec_model, gec_tokenizer, stt_model, emo,         
    onnx_predict                                      
)

# ------------------------------------------------------
# 3. MediaPipe Setup
# ------------------------------------------------------
mp_holistic = mp.solutions.holistic

try:
    holistic_processor = mp_holistic.Holistic(
        static_image_mode=True, 
        model_complexity=1,
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5
    )
    print("âœ… [app] MediaPipe loaded (Static Mode)")
except Exception as e:
    holistic_processor = None
    print(f"âŒ [app] MediaPipe failed: {e}")

# ------------------------------------------------------
# 4. Helper Functions (ì—¬ê¸°ê°€ ëˆ„ë½ë˜ì–´ ì—ëŸ¬ê°€ ë‚¬ë˜ ë¶€ë¶„ì…ë‹ˆë‹¤)
# ------------------------------------------------------
def _extract_kps(frame_bgr, holistic):
    """MediaPipeë¥¼ ì‚¬ìš©í•˜ì—¬ ëœë“œë§ˆí¬(Keypoints) ì¶”ì¶œ"""
    if not holistic: return np.zeros(150, dtype=np.float32)
    
    img = cv2.cvtColor(frame_bgr, cv2.COLOR_RGB2BGR)
    res = holistic.process(img)
    
    # Pose (33ê°œ ì¤‘ í•„ìš”í•œ ê²ƒë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ì „ì²´ ì‚¬ìš©) - ì—¬ê¸°ì„  ì˜ˆì‹œë¡œ 66ê°œ(33*2) ê°€ì •
    pose = np.zeros(66, dtype=np.float32)
    if res.pose_landmarks:
        for i, lm in enumerate(res.pose_landmarks.landmark): 
            pose[i*2], pose[i*2+1] = lm.x, lm.y
            
    # Left Hand (21*2 = 42)
    lh = np.zeros(42, dtype=np.float32)
    if res.left_hand_landmarks:
        for i, lm in enumerate(res.left_hand_landmarks.landmark): 
            lh[i*2], lh[i*2+1] = lm.x, lm.y
            
    # Right Hand (21*2 = 42)
    rh = np.zeros(42, dtype=np.float32)
    if res.right_hand_landmarks:
        for i, lm in enumerate(res.right_hand_landmarks.landmark): 
            rh[i*2], rh[i*2+1] = lm.x, lm.y
        
    # ì´ 150ì°¨ì› (Pose 66 + LH 42 + RH 42 = 150)
    kps = np.concatenate([pose, lh, rh])
    
    # ê°ì§€ëœ ê²Œ ê±°ì˜ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ë¦¬í„´
    if np.sum(np.abs(kps)) < 0.01: return np.zeros(150, dtype=np.float32)
    return kps

def _resample(buffer, target_len=30):
    """í”„ë ˆì„ ìˆ˜ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì ˆ"""
    arr = np.array(buffer, dtype=np.float32)
    if len(arr) == 0: return np.zeros((target_len, 150), dtype=np.float32)
    indices = np.linspace(0, len(arr)-1, target_len, dtype=int)
    return arr[indices]

def _prepare(arr):
    """ëª¨ë¸ ì…ë ¥ ì „ì²˜ë¦¬ (Delta ë“±)"""
    mot = np.zeros_like(arr)
    if len(arr) > 1: mot[1:] = arr[1:] - arr[:-1]
    return np.expand_dims(np.concatenate([arr, mot], axis=1), axis=0)

# ------------------------------------------------------
# 5. Server Config (SocketIO)
# ------------------------------------------------------
app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret!'
CORS(app)

# async_mode='eventlet' ê¶Œì¥ (pip install eventlet í•„ìš”)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='eventlet') 

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
TARGET_FRAMES = 50  

# ì‚¬ìš©ìë³„ ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
# êµ¬ì¡°: { 'session_id': { 'buffer': [], 'room': 'room_id' } }
users = {}

# ------------------------------------------------------
# 6. Socket Events
# ------------------------------------------------------

@socketio.on('join')
def on_join(data):
    room = data.get('room', 'default')
    join_room(room)
    users[request.sid] = {'buffer': [], 'room': room}
    print(f"âœ… User {request.sid} joined room: {room}")
    emit('system_msg', {'msg': f"ìƒˆë¡œìš´ ì‚¬ìš©ìê°€ ì…ì¥í–ˆìŠµë‹ˆë‹¤."}, to=room)

@socketio.on('disconnect')
def on_disconnect():
    if request.sid in users:
        room = users[request.sid]['room']
        del users[request.sid]
        print(f"âŒ User {request.sid} disconnected")
        emit('system_msg', {'msg': "ì‚¬ìš©ìê°€ í‡´ì¥í–ˆìŠµë‹ˆë‹¤."}, to=room)

@socketio.on('sign_data')
def handle_sign_data(data):
    # í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ í”„ë ˆì„ ì²˜ë¦¬
    sid = request.sid
    if sid not in users: return

    try:
        # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
        f_b64 = data['frame'].split(",")[1] if "," in data['frame'] else data['frame']
        img = Image.open(io.BytesIO(base64.b64decode(f_b64))).convert("RGB")
        
        # ì—¬ê¸°ì„œ _extract_kps í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ (ìœ„ì—ì„œ ì •ì˜í–ˆìœ¼ë¯€ë¡œ ì—ëŸ¬ ì•ˆ ë‚¨)
        kps = _extract_kps(cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR), holistic_processor)
        
        users[sid]['buffer'].append(kps)
        curr_len = len(users[sid]['buffer'])
        progress = int((curr_len / TARGET_FRAMES) * 100)

        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ëŠ” ë‚˜ì—ê²Œë§Œ
        emit('progress_update', {'progress': progress}, to=sid)

        if curr_len >= TARGET_FRAMES:
            # 50í”„ë ˆì„ ë„ë‹¬ -> ë¶„ì„ ì‹œì‘
            print(f"ğŸš€ Analyzing Sign for {sid}...")
            buffer = users[sid]['buffer']
            users[sid]['buffer'] = [] # ë²„í¼ ì´ˆê¸°í™”

            resampled = _resample(buffer)
            inp = _prepare(resampled)

            # ëª¨ë¸ ì¶”ë¡ 
            raw_text = "..."
            if encoder_session and vocab:
                sos_id = vocab.stoi.get("<SOS>", 1)
                eos_id = vocab.stoi.get("<EOS>", 2)
                pred_idx = onnx_predict(encoder_session, decoder_session, inp, 50, sos_id, eos_id)
                tokens = [vocab.itos.get(i, "") for i in pred_idx]
                raw_text = " ".join([t for t in tokens if t not in ["<SOS>", "<PAD>", "<EOS>"]]).strip()

            corrected = raw_text
            if gec_model and raw_text:
                try:
                    inp_g = gec_tokenizer(raw_text, return_tensors="pt").to(DEVICE)
                    out_g = gec_model.generate(**inp_g, max_length=50)
                    corrected = gec_tokenizer.decode(out_g[0], skip_special_tokens=True)
                except: pass
            
            # ê²°ê³¼ ë°©ì†¡ (ê°™ì€ ë°© ì‚¬ëŒë“¤ì—ê²Œ ëª¨ë‘ ì „ì†¡)
            room = users[sid]['room']
            emit('chat_message', {
                'type': 'sign',
                'text': raw_text,
                'corrected': corrected,
                'sender': sid
            }, to=room)

    except Exception as e:
        print(f"Sign Error: {e}")
        traceback.print_exc()

@socketio.on('voice_data')
def handle_voice_data(data):
    sid = request.sid
    if sid not in users: return
    room = users[sid]['room']

    try:
        # ì˜¤ë””ì˜¤ ë°”ì´ë„ˆë¦¬ ì €ì¥
        audio_data = data['audio']
        # í™•ì¥ìë¥¼ webmìœ¼ë¡œ ì €ì¥ (ë¸Œë¼ìš°ì € MediaRecorder ê¸°ë³¸ í¬ë§·)
        filename = f"temp_{sid}.webm"
        save_path = os.path.join(BASE_DIR, filename)
        
        with open(save_path, "wb") as f:
            f.write(audio_data)
            
        # STT & ê°ì • ë¶„ì„
        rec_text = ""
        emotion = "neutral"
        
        if stt_model:
            # webm íŒŒì¼ë„ ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ Whisperê°€ ì²˜ë¦¬ ê°€ëŠ¥
            res = stt_model.transcribe(save_path, language="ko")
            rec_text = res.get("text", "").strip()
            
        if emo:
            try:
                emotion, conf, _ = emo.infer_from_file(save_path)
            except: pass
            
        if os.path.exists(save_path): os.remove(save_path)

        # ê²°ê³¼ ë°©ì†¡
        emit('chat_message', {
            'type': 'voice',
            'text': rec_text,
            'emotion': emotion,
            'sender': sid
        }, to=room)

    except Exception as e:
        print(f"Voice Error: {e}")
        traceback.print_exc()

# ------------------------------------------------------
# 7. Routes (HTML/Static Files)
# ------------------------------------------------------
@app.route('/')
def serve_index(): return send_from_directory(FRONTEND_DIR, 'index.html')
@app.route('/demo.html')
def serve_demo(): return send_from_directory(FRONTEND_DIR, 'demo.html')
@app.route('/assets/<path:filename>')
def serve_assets(filename): return send_from_directory(os.path.join(FRONTEND_DIR, 'assets'), filename)

if __name__ == "__main__":
    print(f"\nğŸš€ Socket.IO Server running on port 8000")
    socketio.run(app, host="0.0.0.0", port=8000)